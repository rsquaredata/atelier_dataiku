# Atelier Dataiku - DÃ©ploiement d'un modÃ¨le en API

## Objectif du module

Ce module clÃ´ture notre atelier en vous guidant dans la crÃ©ation, le test et le dÃ©ploiement d'un service API sous **Dataiku Cloud**, Ã  partir d'un modÃ¨le de prÃ©diction dÃ©jÃ  entraÃ®nÃ© (`predict_fraudulent` dans le projet *MLOps Quick Start*).

L'objectif est de transformer un modÃ¨le de machine learning en une API REST capable de rÃ©pondre Ã  des requÃªtes en temps rÃ©el.

---

## Ã‰tape 1 - AccÃ¨s Ã  Dataiku Cloud

Pour commencer :

1. Rendez-vous sur le lien suivant : [https://launchpad-dku.app.dataiku.io/](https://launchpad-dku.app.dataiku.io/)
2. Si un **nÅ“ud (node)** apparaÃ®t :
   - S'il est en **Running**, cliquez sur **Open Instance**.
   - Sinon, cliquez sur **â‹¯ â†’ Turn On** pour le dÃ©marrer.
3. Une fois le workspace lancÃ©, vous Ãªtes prÃªt Ã  crÃ©er votre premier projet Dataiku.

> ğŸ’¡ **Astuce** :  
> Si vous ne parvenez pas Ã  accÃ©der directement au Launchpad, connectez-vous via [https://profile.dataiku.com/](https://profile.dataiku.com/) puis relancez le lien ci-dessus.

---

## Ã‰tape 2 - Activation de l'API Node

1. Dans la **barre latÃ©rale gauche**, cliquez sur **Extensions**.  
2. SÃ©lectionnez **Add an extension**.  
3. Choisissez **API Node**, puis cliquez sur **Add**.  
4. Revenez ensuite dans l'onglet **Overview**.

Vous verrez qu'un **nouveau node** intitulÃ© **API Node** est apparu Ã  cÃ´tÃ© du **Design Node**.

> ğŸ’¡ **Remarque** :  
> Le **Design Node** sert Ã  la conception (datasets, prÃ©paration, modÃ©lisation),  
> tandis que l'**API Node** permet de dÃ©ployer les modÃ¨les sous forme d'API REST.

---

## Ã‰tape 3 - CrÃ©ation du projet Ã  partir d'un template

1. Depuis la page **Overview**, ouvrez votre **Design Node** en cliquant sur **Open Instance**.  
2. Dans l'interface Dataiku :
   - Cliquez sur **+ New Project** (en haut Ã  droite).  
   - SÃ©lectionnez **Learning Project**.  
   - Choisissez le template **MLOps Quick Start**.  
   - Cliquez sur **Go to Flow** pour accÃ©der au diagramme du projet.

> ğŸ’¡ **Astuce** :  
> Ce projet d'exemple prÃ©sente le cycle complet de mise en production d'un modÃ¨le :  
> prÃ©paration â†’ entraÃ®nement â†’ dÃ©ploiement â†’ suivi â†’ API.

---

## Ã‰tape 4 - CrÃ©ation d'une API Ã  partir du modÃ¨le

1. Dans le **Flow**, repÃ©rez le modÃ¨le **predict_fraudulent**.  
2. Cliquez dessus pour ouvrir sa fiche dÃ©taillÃ©e.  
3. Dans la **barre d'outils Ã  droite**, cliquez sur **Create API**.  
4. Renseignez les champs suivants :
   - **API Service name** : `job_posting_api`
   - **Endpoint ID** : `predict_fake_job`
5. Cliquez sur **Append** pour ajouter le modÃ¨le au service d'API.

> ğŸ’¡ **Astuce** :  
> Cette Ã©tape transforme votre modÃ¨le de prÃ©diction en un service d'API rÃ©utilisable.  
> Il pourra ensuite Ãªtre dÃ©ployÃ© sur l'**API Node** et testÃ© en conditions rÃ©elles.

---

## Ã‰tape 5 - Test et publication de l'API

1. Dans l'interface du modÃ¨le, ouvrez l'onglet **Test Queries** (dans le menu gauche).  
2. Cliquez sur **Add Queries** :
   - Indiquez un nombre de requÃªtes, par exemple **5**.  
   - SÃ©lectionnez **From Dataset : Test**.  
   - Cliquez sur **Add**.
3. Les requÃªtes de test sont alors gÃ©nÃ©rÃ©es automatiquement Ã  partir du jeu de donnÃ©es **Test**.
4. Cliquez sur **Run Test Queries** pour les exÃ©cuter et visualiser les rÃ©sultats.
5. Allez dans **Security** â†’ mettez **Authorization** sur **Public** (pour rendre l'API accessible sans clÃ©).

---

### Publication de l'API

1. Dans la barre supÃ©rieure,cliquez sur **â‹¯ â†’ API Designer** pour revenir Ã  la page principale de conception.
2. Cliquez sur **Publish On Deployer**.
3. Laissez le **nom de version par dÃ©faut** (ex : *v1*).  
4. Cliquez sur **Publish** pour dÃ©ployer votre service API.

> âœ… **RÃ©sultat attendu** :  
> Votre modÃ¨le est dÃ©sormais publiÃ© sur l'**API Node** et accessible sous forme d'API REST.  
> Il peut Ãªtre interrogÃ© pour prÃ©dire automatiquement si une offre d'emploi est frauduleuse.

---

## Ã‰tape 6 - DÃ©ploiement sur le Deployer local et test final

1. Dans la barre supÃ©rieure de Dataiku, cliquez sur l'icÃ´ne **en forme de carrÃ© (9 points)** <img width="452" height="90" alt="Capture d'Ã©cran 2025-10-22 015100" src="https://github.com/user-attachments/assets/2c5d7dad-4b29-4c93-8423-d55fd9621614" /> , en haut Ã  droite.  
   > Cette icÃ´ne permet d'accÃ©der Ã  d'autres modules : Automation, Deployer, etc.
2. SÃ©lectionnez **Local Deployer**.
3. Dans le menu, cliquez sur **Deploying API Services**.
4. Dans la barre gauche :
   - Cliquez sur la **version** de votre API (gÃ©nÃ©ralement **v1**).  
   - Cliquez ensuite sur **Deploy**.
5. Confirmez de nouveau en cliquant sur **Deploy**.
6. Vous Ãªtes redirigÃ© vers l'espace de **monitoring** de votre API dÃ©ployÃ©e :
   - suivi des performances,  
   - nombre d'appels,  
   - Ã©tat des requÃªtes.
7. Pour tester :
   - Ouvrez **Run and Test** dans la barre de gauche.  
   - Cliquez sur **Run All** pour exÃ©cuter toutes les requÃªtes de test.

> âœ… **RÃ©sultat attendu** :  
> Tous les tests s'exÃ©cutent correctement.  
> Votre modÃ¨le est dÃ©sormais **dÃ©ployÃ©, testÃ© et opÃ©rationnel** via un service d'API REST dans Dataiku.

---

## Ã‰tape 7 - CrÃ©ation d'un Recipe pour appeler l'API

1. Revenez sur le **Flow** du projet.  
2. Cliquez sur le dataset **Test**.  
3. Dans le panneau de droite, cliquez sur **+ Recipe â†’ Code â†’ Python**  
   (ou **R** selon vos prÃ©fÃ©rences).  
4. Dans la configuration :
   - SÃ©lectionnez **Test** comme dataset d'entrÃ©e.  
   - CrÃ©ez un **nouveau dataset de sortie**, nommÃ© `pred_api`.  
5. Cliquez sur **Create Recipe** pour finaliser la crÃ©ation.

> ğŸ’¡ **Astuce** : ce recipe permettra d'interroger directement l'API et de gÃ©nÃ©rer des prÃ©dictions en lot ou Ã  la demande.

---

## Ã‰tape 8 - ExÃ©cution du Recipe et rÃ©cupÃ©ration des prÃ©dictions

1. Dans le **recipe code**, copiez-collez le code Python suivant :  

```python
# -*- coding: utf-8 -*-
import dataiku
import pandas as pd
import dataikuapi

# --- Connexion Ã  ton API Node ---
client = dataikuapi.APINodeClient(
    "https://api-4f915596-501230dc-dku.eu-west-3.app.dataiku.io",
    "job_postings"  # nom du service
)

# --- Lecture du dataset d'entrÃ©e ---
test = dataiku.Dataset("test")
test_df = test.get_dataframe()

# --- PrÃ©paration d'une liste pour stocker les prÃ©dictions ---
results = []

# --- Boucle sur chaque ligne du dataset ---
for i, row in test_df.iterrows():
    record_to_predict = row.to_dict()  # transforme la ligne en dictionnaire
    try:
        prediction = client.predict_record("predict_fake_job", record_to_predict)
        # Ajoute les rÃ©sultats au dictionnaire
        record_to_predict["prediction_result"] = prediction.get("result")
        record_to_predict["prediction_proba"] = prediction.get("proba") or prediction.get("probabilities", None)
    except Exception as e:
        # En cas d'erreur, on garde trace de la ligne problÃ©matique
        record_to_predict["prediction_result"] = None
        record_to_predict["prediction_proba"] = None
        record_to_predict["error"] = str(e)
    results.append(record_to_predict)

# --- Conversion en DataFrame ---
pred_api_df = pd.DataFrame(results)

# --- Ã‰criture du dataset de sortie ---
pred_api = dataiku.Dataset("pred_api")
pred_api.write_with_schema(pred_api_df)

print(f"âœ… PrÃ©dictions terminÃ©es pour {len(results)} lignes.")

```

> âš ï¸ **Remarque** : adaptez les noms des datasets si vos datasets d'entrÃ©e/sortie diffÃ¨rent (`Test` â†’ dataset d'entrÃ©e, `pred_api` â†’ dataset de sortie).

2. Cliquez sur **Run** pour exÃ©cuter le recipe.  
3. Retournez dans le **Flow** et visualisez le dataset `pred_api` :
   - Construisez le flow ou les sub-flows si nÃ©cessaire.  
   - Observez l'avant-derniÃ¨re ligne : la rÃ©ponse de l'API a bien Ã©tÃ© rÃ©cupÃ©rÃ©e pour chaque ligne du dataset **Test**.

> âš ï¸ **Limitation** :  
> Cependant vous pouvez aussi constater que la colonne stocke toute la rÃ©ponse, malheureusement nous n'avons pas rÃ©ussi Ã  faire mieux que Ã§a, cependant si vous vous en sentez le courage, vous pouvez relever le dÃ©fi et rÃ©soudre ce problÃ¨me
> La colonne de sortie contient actuellement **toute la rÃ©ponse brute** de l'API.  
> ğŸ’¡ **DÃ©fi optionnel** : vous pouvez essayer de parser la rÃ©ponse pour extraire uniquement la prÃ©diction finale.

## Flow Final 
<img width="967" height="448" alt="image" src="https://github.com/user-attachments/assets/2c1478b2-84ee-4aad-a147-bdf9b9938f2b" />

## Ã‰tape 9 - Monitoring des requÃªtes API

1. Dans la barre supÃ©rieure de Dataiku, cliquez sur l'icÃ´ne **en forme de carrÃ© (9 points)** en haut Ã  droite.  
2. SÃ©lectionnez **Deployer â†’ Deploying API Services**.  
3. Dans la section **Deployment**, cliquez sur la carte correspondant Ã  l'API que vous avez mise en production.  
4. Vous accÃ©dez alors Ã  l'espace de **monitoring** de l'API, oÃ¹ vous pouvez observer :  
   - les requÃªtes envoyÃ©es depuis votre script Python,  
   - l'Ã©tat de chaque requÃªte (succÃ¨s ou erreur),  
   - le temps de rÃ©ponse et autres mÃ©triques utiles pour suivre la performance de l'API en production.

> ğŸ’¡ **Astuce** : ce monitoring vous permet de vÃ©rifier que votre pipeline de prÃ©diction fonctionne correctement en production et d'identifier rapidement toute anomalie ou lenteur.

---

## Bilan du module

Vous avez appris Ã  :

- Configurer un **workspace Dataiku Cloud** avec un **API Node**.  
- CrÃ©er un projet MLOps Ã  partir d'un **template**.  
- GÃ©nÃ©rer et tester une **API de prÃ©diction** Ã  partir d'un modÃ¨le existant.  
- DÃ©ployer cette API sur le **Local Deployer** et la tester en production.  
- CrÃ©er un **recipe code** pour interroger l'API et rÃ©cupÃ©rer les prÃ©dictions.

> ğŸ§  **Prochaine Ã©tape** : explorer la section **Monitoring** pour suivre la performance du modÃ¨le en continu (drift, latence, appels rÃ©centsâ€¦).

---

<small>[Retour Ã  la page d'accueil](https://github.com/rsquaredata/atelier_dataiku/blob/main/README.md)</small>

