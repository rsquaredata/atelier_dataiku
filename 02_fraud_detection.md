# Module 2 - D√©tection de fraude : classification d√©s√©quilibr√©e et √©valuation

## Introduction et objectifs

Ce module prolonge le pr√©c√©dent en abordant la d√©tection de fraude √† partir de transactions bancaires.
Le jeu de donn√©es utilis√© est `creditcard.csv`, import√© puis renomm√© `fraud` dans Dataiku Cloud.
L'objectif est d'entra√Æner un mod√®le supervis√© sur un jeu de donn√©es fortement d√©s√©quilibr√©, puis d'√©valuer sa performance.

Objectifs p√©dagogiques :
- Explorer un jeu de donn√©es transactionnel
- G√©rer le d√©s√©quilibre de classes en apprentissage supervis√©
- Effectuer un feature engineering minimal valid√© (ex. `hour` √† partir de `Time`)
- Entra√Æner un mod√®le de classification avec XGBoost
- Interpr√©ter les m√©trriques adapt√©es au d√©s√©quilibre
- Cr√©er un tableau de bord de suivi des pr√©dictions

---

<details>
  <summary><strong></strong></summary>

## Rappels th√©oriques - classification d√©s√©quilibr√©e et m√©triques adapt√©es

### Probl√©matique du d√©s√©quilibre de classes

En d√©tection de fraude, la proportion de transactions frauduleuses est tr√®s faible (souvent inf√©rieure √† 1 %).
Ce d√©s√©quilibre biaise les mod√®les vers la classe majoritaire.
Il n√©cessite des m√©triques et approches adapt√©es.

| M√©thode | Description | Objectif |
|----------|--------------|-----------|
| Undersampling | R√©duction des observations de la classe majoritaire | R√©√©quilibrer le dataset |
| Oversampling | R√©plication de la classe minoritaire | Augmenter les fraudes visibles |
| SMOTE | G√©n√©ration artificielle de cas minoritaires | Mieux r√©partir les fronti√®res de d√©cision |
| Class weights | Pond√©ration automatique des erreurs selon la fr√©quence des classes | R√©duire l‚Äôimpact de la classe majoritaire sans alt√©rer le dataset |

### M√©triques sp√©cifiques

M√©trique locales (d√©pendent du seuil) :
- $\text{Precision} = \frac{TP}{TP+FP}$,
- $\mathrm{Recall} = \frac{TP}{TP+FN}$,
- $\mathrm{F1} = 2\cdot\frac{Precision\cdot Recall}{Precision+Recall}$.

M√©triques globales :
$$AUC-PR = \int_0^1 Precision(Recall)\,d(Recall)$$

$$AUC-ROC = \int_0^1 TPR(FPR)\,d(FPR)$$

### Glossaire int√©gr√©

| Terme | D√©finition |
|--------|-------------|
| Imbalanced dataset | Jeu de donn√©es o√π une classe domine |
| SMOTE | Synthetic Minority Over-sampling Technique |
| AUC-PR | Aire sous la courbe Precision-Recall |
| AUC-ROC | Aire sous la courbe Receiver Operating Characteristic |
| Cost-sensitive learning | Pond√©ration des erreurs selon leur co√ªt |
| XGBoost | Gradient boosting optimis√© pour la vitesse et la pr√©cision |

---

</details>

## TP - D√©tection de fraude

> Pr√©requis : avoir t√©l√©charg√© le fichier `creditcard.csv`.

### A. Import du dataset et identification de la variable cible

1. Dans le **Flow**, ajouter un nouveau dataset : **+ Dataset -> Files -> Upload your files**.  
   - Importer le fichier `creditcard.csv`.  
   - Renommer-le imm√©diatement en **fraud** pour plus de clart√© (**More actions (...) -> Rename -> fraud**).  
2. Ouvrir le dataset **fraud -> Explore**.  
   - Observer la structure : les colonnes sont nomm√©es `V1`, `V2`, etc., plus `Time`, `Amount`, et `Class`.  
   - Identifier la variable cible (indice : `1` = fraude, `0` = transaction normale).  
3. Cr√©er une recette de pr√©paration : **Flow -> + Recipe -> Prepare -> Output : fraud_prepared -> Create**.  
4. Dans la pr√©paration :  
   - **+ Add step -> Rename columns -> Class -> is_fraud**.  
   - V√©rifier dans le dataset **Settings -> Schema** que `is_fraud` est bien de type num√©rique (Integer).  
   - Ex√©cuter la recette : **Run**.  

### Questions

a. Quelle est la variable cible et quelle transformation a √©t√© appliqu√©e ?  
b. Combien le dataset contient-il d'observations et de variables ?  
c. Quelle est la proportion de transactions frauduleuses ?  

<details>
  <summary><strong>üí°</strong></summary>

a. La variable cible est `Class`. On l'a renomm√©e en `is_fraud`, pourquoi d'ailleurs ? (meilleure lisibilit√© m√©tier)   
b. 284807, 31.  
c. 0.17 % de fraudes, soit un fort d√©s√©quilibre.  

</details>

---

### B. Exploration initiale et cr√©ation de la variable `hour`

1. Ouvrir le dataset **fraud_prepared -> Explore**.  
   - Visualiser les premi√®res lignes et rep√©rer la colonne `Time`.  
   - Cette variable indique le nombre de secondes √©coul√©es depuis le d√©but de la collecte.  
2. Cr√©er une nouvelle recette de pr√©paration : **Flow -> + Recipe -> Prepare -> Output : fraud_hour -> Create**.  
3. Dans la pr√©paration :  
   - **+ Add step -> Formula -> Formula for : hour -> Expression : floor(Time / 3600)**.  
   - Cette transformation convertit `Time` (secondes) en heures pour faire appara√Ætre d'√©ventuels motifs temporels.  
   - Ex√©cuter la recette : **Run**.  
4. Ouvrir le dataset **fraud_hour -> Charts**.  
   - Cr√©er un graphique en barres : X = `hour`, Y = `count`.  
   - Ajouter une **facet** sur `is_fraud` pour comparer la r√©partition des fraudes selon l'heure.  

### Questions

a. Quelle est la plage de valeurs de `hour` ?  
b. Certaines heures pr√©sentent-elles davantage de fraudes ?  
c. Pourquoi cette transformation peut-elle aider le mod√®le ?  

<details>
  <summary><strong>üí°</strong></summary>

a. `hour` varie de 0 √† 47 inclus (48 heures).  
b. Les heures nocturnes (2-5h).  
c. Elle capte un comportement temporel, utile pour distinguer des transactions atypiques.  

</details>

---

### C. √âchantillonnage et r√©√©quilibrage

1. S√©lectionner le dataset **fraud_hour** -> **+ Recipe -> Prepare -> Output : fraud_sampled -> Create**.  
2. Param√©trer le sampling (en haut √† gauche dans **Sample settings** :  
   - **Sampling method : Class rebalance(approch nb.records)**, Column : `is_fraud`.  
   - **Nb. records : 5 000 lignes**.  
3. Ex√©cuter la recette : **Run**.  
4. Ouvrir le dataset **fraud_sampled -> Explore** pour v√©rifier la nouvelle proportion de fraudes (nettement plus √©lev√©e).  
> Les 3 op√©rations de transformation qui ont √©t√© r√©alis√©es auraient pu √™tre faite dans un seul bloc prepare, nous avons choisi de le faire en plusieurs pour que vous manipuliez davantage la plateforme.

### Questions

a. Pourquoi est-il n√©cessaire d'√©quilibrer le dataset avant apprentissage ?  
b. Quelles autres techniques permettent de traiter le d√©s√©quilibre ?  

<details>
  <summary><strong>üí°</strong></summary>

a. Un dataset trop d√©s√©quilibr√© pousse le mod√®le √† pr√©dire la classe majoritaire.  
b. Le sous-√©chantillonnage √† 5 000 lignes a √©t√© choisi pour des raisons de performance, mais en pratique un dataset r√©duit peut biaiser la distribution des variables. Pour un projet r√©el, on privil√©giera d'autres techniques : SMOTE, pond√©ration des classes (`class_weight`) ...
</details>

---

### D. Entra√Ænement du mod√®le (XGBoost)

1. S√©lectionner **fraud_sampled -> **Lab ‚Üí AutoML Prediction ‚Üí Create Predict model on credit_risk ‚Üí Choose Algorithms ‚Üí Create**.  
2. Dans la section **Basic -> Target** -> **Target** : `is_fraud` ; **Prediction type** : Two-class classification
3. Inclure toutes les variables sauf `Time` (inutile car redondante avec `hour`).  
4. Dans **Train/Test set**, Mettre train ratio √† 0,8.
5. Dans **Modeling -> Algorithms**, ne garder que **XGBoost**.  
6. Lancer l'entra√Ænement : **Train -> Start**.  
7. Une fois termin√©, cliquer sur le nom du mod√®le √† gauche (XGBoost(s1)) et consulter **Performance -> Metrics ands assertions** : Precision, Recall, F1-score, AUC-ROC.  
8. D√©ployer le mod√®le : **Deploy** (en haut √† droite)
9. Retournez sur le flow, cliquez sur le dernier √©lement (Predict is fraud (binary), puis dans la barre des recipes √† droite choisissez **Score -> Input Dataset : fraud_sampled, Output : fraud_prediction -> Create -> Run**.  

> **Astuce ‚Äì R√©glages de XGBoost** :  L‚Äôinterface Dataiku permet d'ajuster les **hyperparam√®tres XGBoost** sans code : `max_depth`, `learning_rate`, `n_estimators`, etc. L‚Äôonglet **Algorithm settings** offre aussi un grid search int√©gr√©. Ces options am√©liorent la performance du mod√®le tout en conservant une approche visuelle.

### Questions

a. Quelle m√©trique privil√©gier pour √©valuer ce mod√®le ?  
b. Quelle valeur de Recall le mod√®le obtient-il ?  
c. Comment interpr√©ter un Recall √©lev√© avec une Precision faible ?  

<details>
  <summary><strong>üí°</strong></summary>

a. Le Recall et l'AUC-PR sont les plus pertinents pour les jeux tr√®s d√©s√©quilibr√©s.  
b. ‚âà 0.85 selon les runs.  
c. Un Recall √©lev√© indique peu de fraudes manqu√©es, mais beaucoup de faux positifs.  

</details>

> **Choix des m√©triques** : En contexte fortement d√©s√©quilibr√©, l'**AUC-PR** (aire sous la courbe Precision-Recall) est souvent plus informative que l'**AUC-ROC**, car elle met l‚Äôaccent sur la capacit√© du mod√®le √† bien d√©tecter la classe minoritaire sans √™tre biais√©e par la classe majoritaire. Ce point est r√©guli√®rement soulev√© en entretien technique (ex.: [Kharwal, 2023](https://amanxai.com/2023/11/28/machine-learning-interview-questions-on-performance-metrics/) ; [DevInterview.io, 2024](https://github.com/Devinterview-io/model-evaluation-interview-questions), [HireInSouth.com, 2025](https://www.hireinsouth.com/post/machine-learning-interview-questions)).

---

### E. Analyse des r√©sultats et interpr√©tation

1. Ouvrir le mod√®le -> **Interpretation -> Feature importance**.  
   - Rep√©rer les variables dominantes (`V14`, `V3`, `V12`,....).  
2. Ouvrir **Performance -> ROC & PR curve** et **PR Curve**.  
3. Exp√©rimenter le d√©placement du **seuil de classification** pour ajuster le compromis entre Precision et Recall.  

### Questions

a. Quelle variable influence le plus la d√©tection ?  
b. Pourquoi l'AUC-PR compl√®te-t-elle l'AUC-ROC ?  
c. Comment l'ajustement du seuil influe-t-il sur les faux positifs ?  

<details>
  <summary><strong>üí°</strong></summary>

a. `V14` est souvent la plus discriminante.  
b. L'AUC-PR mesure mieux la qualit√© du mod√®le sur la classe minoritaire.  
c. Un seuil plus bas augmente le Recall mais aussi les faux positifs.  

> <small>**Contexte du dataset : `creditcard.csv`**  
> Le jeu de donn√©es provient d'une √©tude men√©e par Andrea Dal Pozzolo (Universit√© de Li√®ge, 2015).  
> Il contient environ 285 000 transactions bancaires europ√©ennes, dont 0,17 % sont frauduleuses.  
> Les variables `V1` √† `V28` sont issues d'une analyse en composantes principales (ACP) des variables r√©elles, masqu√©es pour confidentialit√©.  
> Ces composantes n'ont pas de signification m√©tier directe, mais certaines (notamment `V14`, `V10`, `V12`) sont tr√®s corr√©l√©es √† la fraude.  
> `Time` repr√©sente le nombre de secondes √©coul√©es depuis le d√©but de la collecte, `Amount` le montant, et `Class` la variable cible.  
> </small>

</details>

---

### F. Restitution et tableau de bord

1. Cr√©er un tableau de bord : **+ New -> Dashboard -> fraud_dashboard**.  
2. Ajouter les √©l√©ments suivants :  
   - Feature importance.  
   - Precision-Recall curve et ROC curve.  
   - Confusion matrix.  
   - Table tri√©e des transactions √† haut risque (tri sur `probability_1` d√©croissant).  
3. Publier le dashboard.  

### Questions

a. Quelle est la valeur du F1-score du mod√®le ?  
b. Quelle interpr√©tation donner √† un AUC-PR proche de 1 ?  

<details>
  <summary><strong>üí°</strong></summary>

a. F1-score souvent faible, reflet du compromis entre rappel et pr√©cision.  
b. excellent pouvoir de d√©tection malgr√© le d√©s√©quilibre.  

**Exemple de synth√®se** :  
Le mod√®le XGBoost atteint un **Recall** de 0,85 et un **AUC-PR** de 0,92, ce qui indique une tr√®s bonne capacit√© √† d√©tecter les fraudes malgr√© un fort d√©s√©quilibre de classes.  
Le compromis entre Recall √©lev√© (fraudes d√©tect√©es) et Precision plus faible (faux positifs) reste coh√©rent avec les pratiques bancaires, o√π la priorit√© est de minimiser les fraudes non d√©tect√©es.  
Les variables les plus contributives sont `V14`, `V10` et `V12`, toutes fortement corr√©l√©es √† la probabilit√© de fraude.  
Ce mod√®le constitue un outil d'aide √† la d√©cision permettant d'orienter les v√©rifications manuelles sur les transactions √† risque, dans une logique de surveillance automatis√©e et de ma√Ætrise du risque op√©rationnel.

</details>

---

### V√©rification du Flow

Le Flow doit pr√©senter les noeuds suivants (√† noter que les dashboards ne sont pas visibles dans le flow): 

<img width="1538" height="266" alt="image" src="https://github.com/user-attachments/assets/5e49072e-adf7-4e30-a050-4e336acfcc4f" />

> **Astuce** : Tout projet Dataiku peut √™tre export√© pour √™tre utilis√© dans un autre espace. Cette fonctionnalit√© permet de partager un pipeline complet sans devoir tout recr√©er.
> -  Pour cela, il faut cliquer sur le nom de votre projet (en haut √† gauche quand vous √™tes sur son flow), puis en haut √† droite vous allez cliquez sur **Actions -> Export this project**, puis cochez toutes les cases pour avoir une copie compl√®te du projet. Une fois la pr√©paration termin√©e, cliquez sur **Download** vous aurez allez un dossier .zip .
> -  Pour l'importer dans un nouvel espace il vous suffira de faire (dans l'espace cible) **New Project -> Import project -> Source file : le .zip**


---

## Perspective m√©tier

La d√©tection de fraude en banque repose sur un compromis entre Recall et Precision.
- Un Recall √©lev√© garantit qu'on ne laisse passer presque aucune fraude.
- Une Precision plus faible implique davantage de faux positifs, donc une v√©rification humaine accrue.

Les institutions fixent le seuil selon leur tol√©rance au risque et leurs capacit√©s op√©rationnelles.


---


<small>[**Page d'accueil**](https://github.com/rsquaredata/atelier_dataiku/blob/main/README.md)</small>
