# Module 2 - D√©tection de fraude : classification d√©s√©quilibr√©e et √©valuation
## 1. Introduction et objectifs

Ce module prolonge le pr√©c√©dent en abordant la d√©tection de fraude √† partir de transactions bancaires.
Le jeu de donn√©es utilis√© est `creditcard.csv`, import√© puis renomm√© `fraud` dans Dataiku Cloud.
L'objectif est d'entra√Æner un mod√®le supervis√© sur un jeu de donn√©es fortement d√©s√©quilibr√©, puis d'√©valuer sa performance.

Objectifs p√©dagogiques :
- Explorer un jeu de donn√©es transactionnel
- G√©rer le d√©s√©quilibre de classes en apprentissage supervis√©
- Effectuer un feature engineering minimal valid√© (ex. `hour` √† partir de `Time`)
- Entra√Æner un mod√®le de classification avec XGBoost
- Interpr√©ter les m√©trriques adapt√©es au d√©s√©quilibre
- Cr√©er un tableau de bord de suivi des pr√©dictions

---

## 2. Rappels th√©oriques - classification d√©s√©quilibr√©e et m√©triques adapt√©es

### Probl√©matique du d√©s√©quilibre de classes

En d√©tection de fraude, la proportion de transactions frauduleuses est tr√®s faible (souvent inf√©rieure √† 1 %).
Ce d√©s√©quilibre biaise les mod√®les vers la classe majoritaire.
Il n√©cessite des m√©triques et approches adapt√©es.

| M√©thode | Description | Objectif |
|----------|--------------|-----------|
| Undersampling | R√©duction des observations de la classe majoritaire | R√©√©quilibrer le dataset |
| Oversampling | R√©plication de la classe minoritaire | Augmenter les fraudes visibles |
| SMOTE | G√©n√©ration artificielle de cas minoritaires | Mieux r√©partir les fronti√®res de d√©cision |

### M√©triques sp√©cifiques

M√©trique locales (d√©pendent du seuil) :
- $\text{Precision} = \frac{TP}{TP+FP}$,
- $\mathrm{Recall} = \frac{TP}{TP+FN}$,
- $\mathrm{F1} = 2\cdot\frac{Precision\cdot Recall}{Precision+Recall}$.

M√©triques globales :
$$
AUC-PR = \int_0^1 Precision(Recall)\,d(Recall)
$$

$$
AUC-ROC = \int_0^1 TPR(FPR)\,d(FPR)
$$

### Glossaire int√©gr√©

| Terme | D√©finition |
|--------|-------------|
| Imbalanced dataset | Jeu de donn√©es o√π une classe domine |
| SMOTE | Synthetic Minority Over-sampling Technique |
| AUC-PR | Aire sous la courbe Precision-Recall |
| AUC-ROC | Aire sous la courbe Receiver Operating Characteristic |
| Cost-sensitive learning | Pond√©ration des erreurs selon leur co√ªt |
| XGBoost | Gradient boosting optimis√© pour la vitesse et la pr√©cision |

---

## 3. TP - D√©tection de fraude

> Pr√©-requis : disposer du fichier `creditcard.csv` et rester dans le m√™me projet Dataiku Cloud que pour le scoring.

### A. Import du dataset et identification de la variable cible

1. Dans le **Flow**, ajouter un nouveau dataset : **+ Dataset -> Files -> Upload your files**.  
   - Importer le fichier `creditcard.csv`.  
   - Renommer-le imm√©diatement en **fraud** pour plus de clart√© (**More actions (...) -> Rename -> fraud**).  
2. Ouvrir le dataset **fraud -> Explore**.  
   - Observer la structure : les colonnes sont nomm√©es `V1`, `V2`, etc., plus `Time`, `Amount`, et `Class`.  
   - Identifier la variable cible (indice : `1` = fraude, `0` = transaction normale).  
3. Cr√©er une recette de pr√©paration : **Flow -> + Recipe -> Prepare -> Output : fraud_prepared -> Create**.  
4. Dans la pr√©paration :  
   - **+ Add step -> Rename columns -> Class -> is_fraud**.  
   - V√©rifier dans **Schema** que `is_fraud` est bien de type num√©rique (Integer).  
   - Ex√©cuter la recette : **Run**.  

### Questions

a. Quelle est la variable cible et quelle transformation a √©t√© appliqu√©e ?  
b. Combien le dataset contient-il d'observations et de variables ?  
c. Quelle est la proportion de transactions frauduleuses ?  

<details>
  <summary><strong>üí°</strong></summary>

a. La variable cible est `Class`, renomm√©e en `is_fraud`.  
b. Environ 285 000 observations et 31 variables.  
c. Environ 0.17 % de fraudes, soit un fort d√©s√©quilibre.  

</details>

---

### B. Exploration initiale et cr√©ation de la variable `hour`

1. Ouvrir le dataset **fraud_prepared -> Explore**.  
   - Visualiser les premi√®res lignes et rep√©rer la colonne `Time`.  
   - Cette variable indique le nombre de secondes √©coul√©es depuis le d√©but de la collecte.  
2. Cr√©er une nouvelle recette de pr√©paration : **Flow -> + Recipe -> Prepare -> Output : fraud_hour -> Create**.  
3. Dans la pr√©paration :  
   - **+ Add step -> Formula -> New column : hour -> Expression : floor(Time / 3600)**.  
   - Cette transformation convertit `Time` (secondes) en heures pour faire appara√Ætre d'√©ventuels motifs temporels.  
   - Ex√©cuter la recette : **Run**.  
4. Ouvrir le dataset **fraud_hour -> Explore -> Charts**.  
   - Cr√©er un graphique en barres : X = `hour`, Y = `count`.  
   - Ajouter une **facet** sur `is_fraud` pour comparer la r√©partition des fraudes selon l'heure.  

### Questions

a. Quelle est la plage de valeurs de `hour` ?  
b. Certaines heures pr√©sentent-elles davantage de fraudes ?  
c. Pourquoi cette transformation peut-elle aider le mod√®le ?  

<details>
  <summary><strong>üí°</strong></summary>

a. `hour` varie de 0 √† environ 47 (48 heures).  
b. Les heures nocturnes peuvent pr√©senter un l√©ger exc√®s de fraudes.  
c. Elle capte un comportement temporel, utile pour distinguer des transactions atypiques.  

</details>

---

### C. √âchantillonnage et r√©√©quilibrage

1. S√©lectionner le dataset **fraud_hour** -> **+ Recipe -> Sampling -> Output : fraud_sampled -> Create**.  
2. Param√©trer le sampling :  
   - **Sampling type : Stratified sampling** sur `is_fraud`.  
   - **Sample size : 5000 lignes**.  
3. Ex√©cuter la recette : **Run**.  
4. Ouvrir le dataset **fraud_sampled -> Explore** pour v√©rifier la nouvelle proportion de fraudes (nettement plus √©lev√©e).  

### Questions

a. Pourquoi est-il n√©cessaire d'√©quilibrer le dataset avant apprentissage ?  
b. Quelles autres techniques permettent de traiter le d√©s√©quilibre ?  

<details>
  <summary><strong>üí°</strong></summary>

a. Un dataset trop d√©s√©quilibr√© pousse le mod√®le √† pr√©dire la classe majoritaire.  
b. Alternatives : oversampling, SMOTE, pond√©ration des classes (`class_weight`).  

</details>

---

### D. Entra√Ænement du mod√®le (XGBoost)

1. S√©lectionner **fraud_sampled -> Lab -> + New -> Visual analysis -> Predict**.  
2. D√©finir les param√®tres :  
   - **Target variable : is_fraud**.  
   - **Prediction type : Binary classification**.  
3. Inclure toutes les variables sauf `Time` (inutile car redondante avec `hour`).  
4. Dans **Design -> Algorithms**, ne garder que **XGBoost**.  
5. Dans **Settings -> Train/Test split**, choisir 80 % / 20 %.  
6. Lancer l'entra√Ænement : **Train -> Start**.  
7. Une fois termin√©, consulter **Performance -> Metrics** : Precision, Recall, F1-score, AUC-PR, AUC-ROC.  
8. D√©ployer le mod√®le : **Deploy -> Create Scoring recipe -> Output : fraud_prediction -> Create -> Run**.  

### Questions

a. Quelle m√©trique privil√©gier pour √©valuer ce mod√®le ?  
b. Quelle valeur de Recall le mod√®le obtient-il ?  
c. Comment interpr√©ter un Recall √©lev√© avec une Precision faible ?  

<details>
  <summary><strong>üí°</strong></summary>

a. Le Recall et l'AUC-PR sont les plus pertinents pour les jeux tr√®s d√©s√©quilibr√©s.  
b. Typiquement autour de 0.85 selon les runs.  
c. Un Recall √©lev√© indique peu de fraudes manqu√©es, mais beaucoup de faux positifs.  

</details>

---

### E. Analyse des r√©sultats et interpr√©tation

1. Ouvrir le mod√®le -> **Interpretation -> Feature importance**.  
   - Rep√©rer les variables dominantes (`V14`, `V10`, `V12`, et √©ventuellement `hour`).  
2. Ouvrir **Performance -> ROC curve** et **Precision-Recall curve**.  
3. Exp√©rimenter le d√©placement du **seuil de classification** pour ajuster le compromis entre Precision et Recall.  

### Questions

a. Quelle variable influence le plus la d√©tection ?  
b. Pourquoi l'AUC-PR compl√®te-t-elle l'AUC-ROC ?  
c. Comment l'ajustement du seuil influe-t-il sur les faux positifs ?  

<details>
  <summary><strong>üí°</strong></summary>

a. `V14` est souvent la plus discriminante.  
b. L'AUC-PR mesure mieux la qualit√© du mod√®le sur la classe minoritaire.  
c. Un seuil plus bas augmente le Recall mais aussi les faux positifs.  

> <small>**Contexte du dataset : `creditcard.csv`**  
> Le jeu de donn√©es provient d'une √©tude men√©e par Andrea Dal Pozzolo (Universit√© de Li√®ge, 2015).  
> Il contient environ 285 000 transactions bancaires europ√©ennes, dont 0,17 % sont frauduleuses.  
> Les variables `V1` √† `V28` sont issues d'une analyse en composantes principales (ACP) des variables r√©elles, masqu√©es pour confidentialit√©.  
> Ces composantes n'ont pas de signification m√©tier directe, mais certaines (notamment `V14`, `V10`, `V12`) sont tr√®s corr√©l√©es √† la fraude.  
> `Time` repr√©sente le nombre de secondes √©coul√©es depuis le d√©but de la collecte, `Amount` le montant, et `Class` la variable cible.  
> </small>

</details>

---

### F. Restitution et tableau de bord

1. Cr√©er un tableau de bord : **+ New -> Dashboard -> fraud_dashboard**.  
2. Ajouter les √©l√©ments suivants :  
   - Feature importance.  
   - Precision-Recall curve et ROC curve.  
   - Confusion matrix.  
   - Table tri√©e des transactions √† haut risque (tri sur `probability_1` d√©croissant).  
   - Bloc **Text** avec synth√®se des r√©sultats.  
3. Publier le dashboard.  

### Questions

a. Quelle est la valeur du F1-score du mod√®le ?  
b. Quelle interpr√©tation donner √† un AUC-PR proche de 1 ?  

<details>
  <summary><strong>üí°</strong></summary>

a. F1-score souvent faible, reflet du compromis entre rappel et pr√©cision.  
b. excellent pouvoir de d√©tection malgr√© le d√©s√©quilibre.  

</details>

---

### V√©rification du Flow

Flow final attendu :  

```
creditcard.csv -> fraud -> fraud_prepared -> fraud_hour -> fraud_sampled -> fraud_prediction -> fraud_dashboard
```

Un mod√®le **fraud_xgboost_model** doit appara√Ætre dans le **Lab**.  

---

## 4. Perspective m√©tier

La d√©tection de fraude en banque repose sur un compromis entre Recall et Precision.
- Un Recall √©lev√© garantit qu'on ne laisse passer presque aucune fraude.
- Une Precision plus faible implique davantage de faux positifs, donc une v√©rification humaine accrue.

Les institutions fixent le seuil selon leur tol√©rance au risque et leurs capacit√©s op√©rationnelles.

---
