# Module 1 - Scoring de clients : exploration et modÃ©lisation supervisÃ©e

## Introduction et objectifs

Ce module guide la crÃ©ation d'un modÃ¨le de scoring de crÃ©dit sous Dataiku Cloud.
Le jeu de donnÃ©es utilisÃ© est `credit_scoring.csv`, importÃ© puis renommÃ© `risk` dans Dataiku.
Les Ã©tapes suivantes permettent de prÃ©parer les donnÃ©es, d'entraÃ®ner un modÃ¨le supervisÃ© et d'interprÃ©ter ses rÃ©sultats.

Objectifs pÃ©dagogiques :
- Importer, renommer et explorer un jeu de donnÃ©es dans Dataiku Cloud
- Nettoyer et transformer les variables pour la modÃ©lisation
- EntraÃ®ner et Ã©valuer un modÃ¨le de classification binaire
- InterprÃ©ter les mÃ©triques principales et les variables explicatives
- Construire un tableau de bord de restitution

---

<details>
  <summary><strong></strong></summary>

  ## Rappels thÃ©oriques - statistiques descriptives et classification supervisÃ©e

### Variables
- Variable cible : binaire $y \in \{0,1\}$ (1 = bon payeur, 0 = mauvais payeur)
- Variables explicatives : quantitatives  (revenu, montant, durÃ©e) ou qualitatives (emploi, situation familiale)

### RÃ©gression logistique

$$P(y_i=1 \mid X_i)=\frac{1}{1+e^{-(\beta_0+\beta_1x_{i1}+\ldots+\beta_p x_{ip})}}$$

Chaque coefficient $\beta_j$ reflÃ¨te l'influence de la variable explicative $x_j$ sur la probabilitÃ© d'appartenir Ã  la classe 1 
RÃ©gularisation L1 (Lasso) : $\lambda\sum|\beta_j|$ ; L2 (Ridge) : $\lambda\sum\beta_j^2$

### Ã‰valuation du modÃ¨le

| Indicateur | Formule | InterprÃ©tation |
|-------------|----------|----------------|
| Accuracy | $$\frac{TP+TN}{TP+TN+FP+FN}$$ | Pourcentage de prÃ©dictions correctes |
| Recall (SensibilitÃ©) | $$\frac{TP}{TP+FN}$$ | CapacitÃ© Ã  dÃ©tecter les cas positifs |
| Precision | $$\frac{TP}{TP+FP}$$ | FiabilitÃ© des cas prÃ©dits positifs |
| F1-score | $$2\,\frac{\text{Precision}\times \text{Recall}}{\text{Precision}+\text{Recall}}$$ | Compromis Precision-Recall |
| AUC (ROC) | Aire sous la courbe ROC | Pouvoir discriminant global |

### CorrÃ©lation et colinÃ©aritÃ©

$$r_{XY}=\frac{\mathrm{Cov}(X,Y)}{s_X s_Y},\quad |r|>0{,}8 \Rightarrow \text{variables redondantes.}$$

### Glossaire intÃ©grÃ©

| Terme | DÃ©finition |
|--------|-------------|
| AutoML | EntraÃ®nement automatique de plusieurs algorithmes |
| Feature importance | Poids relatif d'une variable dans la performance |
| Overfitting | Sur-ajustement aux donnÃ©es d'entraÃ®nement |
| Threshold | Seuil de probabilitÃ© sÃ©parant les classes 0/1 |
| AUC | Aire sous la courbe ROC, proche de 1 = meilleur modÃ¨le |

---

</details>

## TP - Scoring clients

> PrÃ©requis : avoir activÃ© son compte Dataiku Cloud et tÃ©lÃ©chargÃ© le fichier `credit_scoring.csv` sur sa machine.

### A. CrÃ©ation du projet et import du dataset

1. Ouvrir <https://profile.dataiku.com/> â†’ Start free trial â†’ Dataiku Cloud
2. CrÃ©er un nouveau projet : **+ New Project â†’ Blank project**
   - Project name : `Dataiku_Bank_[PrenomNom]`
   - Key : `DB_[initiales]`
3. Importer le fichier : **Flow (vous y Ãªtes dÃ©jÃ  normalement) â†’ + Add Item (en haut Ã  droite) â†’ Upload â†’ Select Files** â†’ sÃ©lectionner `credit_scoring.csv` â†’ Create
4. Renommer le dataset : **Actions (Ã  droite) â†’ Rename â†’ risk**
5. VÃ©rifier le schÃ©ma : **Onglet "Settings"(dans le dataset) â†’ Schema â†’** vÃ©rifier les types (numÃ©rique vs catÃ©goriel), s'ils sont tous en string cliquez sur **CHECK NOW** â†’ **INFER TYPES FROM DATA** â†’ Save

### Questions

a. Quelle est la variable cible ?  
b. Combien le dataset contient-il d'observations et de variables (Explore) ?

<details>
  <summary><strong>ğŸ’¡</strong></summary>

a. Variable cible : `credit_risk`  
b. Dimensions : 1 000 observations et 21 variables

</details>

---

### B. Exploration initiale

1. Ouvrir `risk` â†’ **Explore**
2. **Charts** : histogrammes pour `amount`, `duration`, `age` (utilisez Count of records pour Y). Vous pouvez crÃ©er plusieurs graphiques ou en regrouper. 
3. **Statistics â†’ New Card â†’ Automatically suggest analyses â†’ Cocher les 4 features dans la partie droite** : Vous avez maintenant plusieurs analyses gÃ©nÃ©rÃ©es
4. **Missing values** : Utilisez les analyses statistiques gÃ©nÃ©rÃ©es pour repÃ©rer s'il y a d'Ã©ventuelles valeurs manquantes 
5. **Correlation matrix** : Utilisez la matrice de corrÃ©lation gÃ©nÃ©rÃ©e pour repÃ©rer les variables corrÃ©lÃ©es
6. **Charts â†’ +Chart(en bas) â†’ Scatter** (`amount` vs `duration`) ; **Facet** par `credit_risk`

### Questions 

a. A partir des analyses prÃ©cÃ©dentes, quelle variable prÃ©sente la plus forte asymÃ©trie ?  
b. Quelle variable semble la plus corrÃ©lÃ©e au risque ?  
c. Y a-t-il des valeurs manquantes ?  
d. Quelles relations observe-t-on entre `amount`, `age` et `duration` ?

<details>
  <summary><strong>ğŸ’¡</strong></summary>

a. `amount` (trÃ¨s asymÃ©trique)  
b. `duration` (corrÃ©lation nÃ©gative modÃ©rÃ©e avec `credit_risk`)  
c. Aucune valeur manquante  
d. `age` faiblement positif avec bon crÃ©dit ; `amount` et `duration` associÃ©s Ã  plus de dÃ©fauts quand ils augmentent

</details>

> **Astuce - Bonne pratique** : aprÃ¨s avoir construit plusieurs recipes de prÃ©paration (Prepare, Code, Joinâ€¦), penser Ã  nommer clairement les sorties et Ã  activer la documentation automatique dans le Flow (**More actions â†’ Edit project documentation**). En fin de projet, cette documentation sert de traÃ§abilitÃ© interne et peut Ãªtre exportÃ©e comme rapport dâ€™audit.

---

### C. PrÃ©paration des donnÃ©es et Code recipe

1. Depuis le **Flow**, sÃ©lectionner `risk` â†’ **+ Recipe â†’ Prepare â†’ Output : risk_prepared â†’ Create**
2. Renommer les noms de colonnes : **Columns â†’ Rename columns** (`personal_status_sex`, `credit_history`, etc.)
3. CrÃ©er la variable `payment_intensity` : **+ Add a new step â†’ Formula â†’ Formula for : payment_intensity â†’ Expression : amount /duration**
4. Recoder `personal_status_sex` : **+ Add a new step â†’ Create If... Then... Else Statement** (aussi possible en utilisant Formula)
   - Si `personal_status_sex` âˆˆ {female div/dep/mar, female single} alors 1, sinon 0
   - Forcer le type en **Integer**
5. Encodage de `job` : **+ Add step â†’ Unfold â†’ Column : job** (la variable job peut ensuite Ãªtre supprimÃ©)
6. ExÃ©cuter la recette : **Run puis Allez dans Flow** et vÃ©rifiez la crÃ©ation de `risk_prepared`

#### Code recipe

1. **Flow â†’ + Recipe â†’ Code â†’ Python**
2. Input : `risk_prepared` ; Output : `risk_prepared` (ou `risk_prepared_code` si remplacer ne passe pas)
3. Coller le code suivant :

```python
# -*- coding: utf-8 -*-
import dataiku
import pandas as pd, numpy as np
from dataiku import pandasutils as pdu

# Read recipe inputs
risk_prepared = dataiku.Dataset("risk_prepared")
risk_prepared_df = risk_prepared.get_dataframe()

risk_prepared_df["log_amount"] = np.log1p(risk_prepared_df["amount"])
risk_prepared_code_df = risk_prepared_df # For this sample code, simply copy input to output


# Write recipe outputs
risk_prepared_code = dataiku.Dataset("risk_prepared_code")
risk_prepared_code.write_with_schema(risk_prepared_code_df)
```

4. ExÃ©cuter la recette : **Run â†’** vÃ©rifier l'apparition de la colonne `log_amount`

### Questions

a. Combien de colonnes reste-t-il aprÃ¨s prÃ©paration ?  
b. Quelle transformation amÃ©liore la lisibilitÃ© des montants ?  
c. Pourquoi utiliser `log1p` plutÃ´t que `log` ?  
d. Quelle est la moyenne et l'Ã©cart-type de `log_amount` ?

<details>
  <summary><strong>ğŸ’¡</strong></summary>

a. 26  
b. La transformation logarithmique  
c. `log1p` calcule $\log(1+x)$ : il gÃ¨re $x=0$ et stabilise les trÃ¨s petites valeurs, utile en finance (micro-paiements, taux d'intÃ©rÃªt, arrondis, ...)  
d. Moyenne : â‰ˆ 7.15 ; Ã©cart-type : â‰ˆ 0.88

</details>

---

### D. Construction du modÃ¨le

1. SÃ©lectionner `risk_prepared` (ou `risk_prepared_code`) â†’ **Lab â†’ AutoML Prediction â†’ Create Predict model on credit_risk â†’ Choose Algorithms â†’ Create**
2. Target : `credit_risk` ; Prediction type : Two-class classification
3. Features : garder toutes les colonnes utiles, exclure identifiants
4. **Design â†’ Algorithms** : cocher Logistic Regression, Random Forest, XGBoost
5. **Result â†’ Train â†’ Start**
6. **Performance** : observer Accuracy, Recall, Precision, F1, AUC
7. **Deploy â†’ Create Scoring recipe â†’ Output : risk_predictions â†’ Create â†’ Run**
8. Une fois le lancement terminÃ©, vous pouvez revenir dans **Design** changer les paramÃ¨tres, les modÃ¨les,etc.. afin d'essayer d'obtenir de meilleurs mesures, vous pouvez ensuite naviguer entre sessions, models et tables pour comparer les diffÃ©rents modÃ¨les essayÃ©s

### Questions

a. Ã€ votre avis, quelle mÃ©trique faut-il privilÃ©gier en contexte bancaire ?  
b. Y a-t-il des variables problÃ©matiques ?  
b. Quel algorithme offre le meilleur compromis Precision/Recall ?  

<details>
  <summary><strong>ğŸ’¡</strong></summary>

a. Recall si le but est de minimiser les faux nÃ©gatifs (ne pas accorder de prÃªt risquÃ©)  
b. **Ã‰thique**â€¯: attention aux variables sensibles (`sex`, `age`)  
b. XGBoost ou Random Forest selon les runs  

</details>

---

### 3.5. InterprÃ©tation et restitution

1. Depuis la page du modÃ¨le : **Interpretation â†’ Feature importance, Partial dependence**
2. CrÃ©er un dashboard : **+ New â†’ Dashboard â†’ risk_dashboard**
3. Ajouter : Feature importance, Confusion matrix, et un bloc **Text** avec une synthÃ¨se des rÃ©sultats
4. Publier le dashboard

### Questions

a. Quelle variable contribue le plus Ã  la prÃ©diction ?  
b. Comment le seuil influence-t-il la matrice de confusion ?

<details>
  <summary><strong>ğŸ’¡</strong></summary>

a. `duration`  
b. Augmenter le seuil = augmente les FP (perte potentielle de clients) / baisser le seuil = augmente les FN (risque de dÃ©faut) â†’ seuil Ã  dÃ©terminer selon la tolÃ©rance au risque.

**Exemple de synthÃ¨se pour le dashboard** : 
Ce modÃ¨le de scoring prÃ©dit le risque de dÃ©faut avec une AUC de 0,82 (avis ?). Les variables importantes sont la durÃ©e et le montant du prÃªt, toutes deux corrÃ©lÃ©es nÃ©gativement Ã  la probabilitÃ© de remboursement. Ce modÃ¨le constitue un outil d'aide Ã  la dÃ©cision pour les conseillers.

</details>

---

### VÃ©rification du Flow

Le Flow doit prÃ©senter les noeuds suivants :

```
risk â†’ risk_prepared â†’ (code) â†’ risk_predictions â†’ risk_dashboard
```

Si un dataset intermÃ©diaire est crÃ©Ã© (par exemple `risk_prepared_code`), il doit Ãªtre l'entrÃ©e de la recette de scoring.

> **Astuce** : tout projet Dataiku peut Ãªtre exportÃ© sous forme de *bundle* (**Administration â†’ Bundles â†’ Export**) pour Ãªtre rÃ©utilisÃ© sur un autre espace. Cette fonctionnalitÃ© permet de partager un pipeline complet sans devoir tout recrÃ©er.

<details>
  <summary><strong></strong></summary>

---
   
## Perspective mÃ©tier

Le scoring de clients estime la probabilitÃ© de dÃ©faut de paiement d'un client dans le cadre d'octroi d'un crÃ©dit.
En contexte bancaire :

- UtilitÃ© : prÃ©-tri des dossiers pour Ã©tude plus poussÃ©e des cas risquÃ©s
- MÃ©trique : Recall prioritaire car les faux nÃ©gatifs sont coÃ»teux
- Ã‰thique : variables sensibles (sexe, Ã¢ge) Ã  encadrer/contrÃ´ler/justifier, voire exclure, en cas de mise en prod rÃ©elle
- Variables clÃ©s : `duration`, `amount`, `payment_intensity`

---

## Ressources

- Dataiku Academy - *Classification Models* : <https://academy.dataiku.com/latest/course-detail/dataiku-ml-practitioner.html>
- Documentation - *Machine Learning in Dataiku* : <https://doc.dataiku.com/dss/latest/machine-learning/index.html>
- Hastie, Tibshirani, Friedman - *The Elements of Statistical Learning* (PDF libre) : <https://hastie.su.domains/ElemStatLearn/>

</details>

---

<small>[**Page d'accueil**](https://github.com/rsquaredata/atelier_dataiku/blob/main/README.md)</small>
