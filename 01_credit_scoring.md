# Module 1 - Scoring de clients : exploration et mod√©lisation supervis√©e

## Introduction et objectifs

Ce module guide la cr√©ation d'un mod√®le de scoring de cr√©dit sous Dataiku Cloud.
Le jeu de donn√©es utilis√© est `credit_scoring.csv`, import√© puis renomm√© `risk` dans Dataiku.
Les √©tapes suivantes permettent de pr√©parer les donn√©es, d'entra√Æner un mod√®le supervis√© et d'interpr√©ter ses r√©sultats.

Objectifs p√©dagogiques :
- Importer, renommer et explorer un jeu de donn√©es dans Dataiku Cloud
- Nettoyer et transformer les variables pour la mod√©lisation
- Entra√Æner et √©valuer un mod√®le de classification binaire
- Interpr√©ter les m√©triques principales et les variables explicatives
- Construire un tableau de bord de restitution

---

<details>
  <summary><strong></strong></summary>

  ## Rappels th√©oriques - statistiques descriptives et classification supervis√©e

### Variables
- Variable cible : binaire $y \in \{0,1\}$ (1 = bon payeur, 0 = mauvais payeur)
- Variables explicatives : quantitatives  (revenu, montant, dur√©e) ou qualitatives (emploi, situation familiale)

### R√©gression logistique

$$P(y_i=1 \mid X_i)=\frac{1}{1+e^{-(\beta_0+\beta_1x_{i1}+\ldots+\beta_p x_{ip})}}$$

Chaque coefficient $\beta_j$ refl√®te l'influence de la variable explicative $x_j$ sur la probabilit√© d'appartenir √† la classe 1 
R√©gularisation L1 (Lasso) : $\lambda\sum|\beta_j|$ ; L2 (Ridge) : $\lambda\sum\beta_j^2$

### √âvaluation du mod√®le

| Indicateur | Formule | Interpr√©tation |
|-------------|----------|----------------|
| Accuracy | $$\frac{TP+TN}{TP+TN+FP+FN}$$ | Pourcentage de pr√©dictions correctes |
| Recall (Sensibilit√©) | $$\frac{TP}{TP+FN}$$ | Capacit√© √† d√©tecter les cas positifs |
| Precision | $$\frac{TP}{TP+FP}$$ | Fiabilit√© des cas pr√©dits positifs |
| F1-score | $$2\,\frac{\text{Precision}\times \text{Recall}}{\text{Precision}+\text{Recall}}$$ | Compromis Precision-Recall |
| AUC (ROC) | Aire sous la courbe ROC | Pouvoir discriminant global |

### Corr√©lation et colin√©arit√©

$$r_{XY}=\frac{\mathrm{Cov}(X,Y)}{s_X s_Y},\quad |r|>0{,}8 \Rightarrow \text{variables redondantes.}$$

### Glossaire int√©gr√©

| Terme | D√©finition |
|--------|-------------|
| AutoML | Entra√Ænement automatique de plusieurs algorithmes |
| Feature importance | Poids relatif d'une variable dans la performance |
| Overfitting | Sur-ajustement aux donn√©es d'entra√Ænement |
| Threshold | Seuil de probabilit√© s√©parant les classes 0/1 |
| AUC | Aire sous la courbe ROC, proche de 1 = meilleur mod√®le |

---

</details>

## TP - Scoring clients

> Pr√©requis : avoir activ√© son compte Dataiku Cloud et t√©l√©charg√© le fichier `credit_scoring.csv` sur sa machine.

### A. Cr√©ation du projet et import du dataset

1. Ouvrir <https://profile.dataiku.com/> ‚Üí Start free trial ‚Üí Dataiku Cloud (si vous n'√™tes pas redirig√© sur Dataiku cloud, cliquez sur ce lien <https://launchpad-dku.app.dataiku.io/> , choisissez AWS Paris et nommez votre workspace
2. Un node s'affiche s'il est en **Running** cliquez sur Open Instance, sinon cliquez sur **...**  plus haut et puis **Turn On** 
3. Cr√©er un nouveau projet : **+ New Project ‚Üí Blank project**
   - Project name : `Dataiku_Bank_[PrenomNom]`
   - Key : `DB_[initiales]`
4. Importer le fichier : **Flow (vous y √™tes d√©j√† normalement) ‚Üí + Add Item (en haut √† droite) ‚Üí Upload ‚Üí Select Files** ‚Üí s√©lectionner `credit_scoring.csv` ‚Üí Create
5. Renommer le dataset : **Actions (√† droite) ‚Üí Rename ‚Üí risk**
6. V√©rifier le sch√©ma : **Onglet "Settings"(dans le dataset) ‚Üí Schema ‚Üí** v√©rifier les types (num√©rique vs cat√©goriel), s'ils sont tous en string cliquez sur **CHECK NOW** ‚Üí **INFER TYPES FROM DATA** ‚Üí Save

### Questions

a. Quelle est la variable cible ?  
b. Combien le dataset contient-il d'observations et de variables (Explore) ?

<details>
  <summary><strong>üí°</strong></summary>

a. Variable cible : `credit_risk`  
b. Dimensions : 1 000 observations et 21 variables

</details>

---

### B. Exploration initiale

1. Ouvrir `risk` ‚Üí **Explore**
2. **Charts** : histogrammes pour `amount`, `duration`, `age` (utilisez Count of records pour Y). Vous pouvez cr√©er plusieurs graphiques ou en regrouper. 
3. **Statistics ‚Üí New Card ‚Üí Automatically suggest analyses ‚Üí Cocher les 4 features dans la partie droite** : Vous avez maintenant plusieurs analyses g√©n√©r√©es
4. **Missing values** : Utilisez les analyses statistiques g√©n√©r√©es pour rep√©rer s'il y a d'√©ventuelles valeurs manquantes 
5. **Correlation matrix** : Utilisez la matrice de corr√©lation g√©n√©r√©e pour rep√©rer les variables corr√©l√©es
6. **Charts ‚Üí +Chart(en bas) ‚Üí Scatter** (`amount` vs `duration`) ; **Facet** par `credit_risk`

### Questions 

a. A partir des analyses pr√©c√©dentes, quelle variable pr√©sente la plus forte asym√©trie ?  
b. Quelle variable semble la plus corr√©l√©e au risque ?  
c. Y a-t-il des valeurs manquantes ?  
d. Quelles relations observe-t-on entre `amount`, `age` et `duration` ?

<details>
  <summary><strong>üí°</strong></summary>

a. `amount` (tr√®s asym√©trique)  
b. `duration` (corr√©lation n√©gative mod√©r√©e avec `credit_risk`)  
c. Aucune valeur manquante  
d. `age` faiblement positif avec bon cr√©dit ; `amount` et `duration` associ√©s √† plus de d√©fauts quand ils augmentent

</details>

> **Astuce - Bonne pratique** : apr√®s avoir construit plusieurs recipes de pr√©paration (Prepare, Code, Join‚Ä¶), penser √† nommer clairement les sorties et √† activer la documentation automatique dans le Flow (**More actions ‚Üí Edit project documentation**). En fin de projet, cette documentation sert de tra√ßabilit√© interne et peut √™tre export√©e comme rapport d‚Äôaudit.

---

### C. Pr√©paration des donn√©es et Code recipe

1. Depuis le **Flow**, s√©lectionner `risk` ‚Üí **+ Recipe ‚Üí Prepare ‚Üí Output : risk_prepared ‚Üí Create**
2. Renommer les noms de colonnes : **Columns ‚Üí Rename columns** (`personal_status_sex`, `credit_history`, etc.)
3. Cr√©er la variable `payment_intensity` : **+ Add a new step ‚Üí Formula ‚Üí Formula for : payment_intensity ‚Üí Expression : amount /duration**
4. Recoder `personal_status_sex` : **+ Add a new step ‚Üí Create If... Then... Else Statement** (aussi possible en utilisant Formula)
   - Si `personal_status_sex` ‚àà {female div/dep/mar, female single} alors 1, sinon 0
   - Forcer le type en **Integer**
5. Encodage de `job` : **+ Add step ‚Üí Unfold ‚Üí Column : job** (la variable job peut ensuite √™tre supprim√©)
6. Ex√©cuter la recette : **Run puis Allez dans Flow** et v√©rifiez la cr√©ation de `risk_prepared`

#### Code recipe

1. **Flow ‚Üí + Recipe ‚Üí Code ‚Üí Python**
2. Input : `risk_prepared` ; Output : `risk_prepared` (ou `risk_prepared_code` si remplacer ne passe pas)
3. Coller le code suivant :

```python
# -*- coding: utf-8 -*-
import dataiku
import pandas as pd, numpy as np
from dataiku import pandasutils as pdu

# Read recipe inputs
risk_prepared = dataiku.Dataset("risk_prepared")
risk_prepared_df = risk_prepared.get_dataframe()

risk_prepared_df["log_amount"] = np.log1p(risk_prepared_df["amount"])
risk_prepared_code_df = risk_prepared_df # For this sample code, simply copy input to output


# Write recipe outputs
risk_prepared_code = dataiku.Dataset("risk_prepared_code")
risk_prepared_code.write_with_schema(risk_prepared_code_df)
```

4. Ex√©cuter la recette : **Run ‚Üí** v√©rifier l'apparition de la colonne `log_amount`

### Questions

a. Combien de colonnes reste-t-il apr√®s pr√©paration ?  
b. Quelle transformation am√©liore la lisibilit√© des montants ?  
c. Pourquoi utiliser `log1p` plut√¥t que `log` ?  
d. Quelle est la moyenne et l'√©cart-type de `log_amount` ?

<details>
  <summary><strong>üí°</strong></summary>

a. 26  
b. La transformation logarithmique  
c. `log1p` calcule $\log(1+x)$ : il g√®re $x=0$ et stabilise les tr√®s petites valeurs, utile en finance (micro-paiements, taux d'int√©r√™t, arrondis, ...)  
d. Moyenne : ‚âà 7.15 ; √©cart-type : ‚âà 0.88

</details>

---

### D. Construction du mod√®le

1. S√©lectionner `risk_prepared` (ou `risk_prepared_code`) ‚Üí **Lab ‚Üí AutoML Prediction ‚Üí Create Predict model on credit_risk ‚Üí Choose Algorithms ‚Üí Create**
2. Target : `credit_risk` ; Prediction type : Two-class classification
3. Features : garder toutes les colonnes utiles, exclure identifiants
4. **Design ‚Üí Algorithms** : cocher Logistic Regression, Random Forest, XGBoost
5. **Result ‚Üí Train ‚Üí Start**
6. **Performance** : observer Accuracy, Recall, Precision, F1, AUC
7. Une fois le lancement termin√©, vous pouvez revenir dans **Design** changer les param√®tres, les mod√®les,etc.. afin d'essayer d'obtenir de meilleurs mesures, vous pouvez ensuite naviguer entre sessions, models et tables pour comparer les diff√©rents mod√®les essay√©s
8. Cliquez sur le mod√®le que vous souhaitez retenir puis : **Deploy**

### Questions

a. √Ä votre avis, quelle m√©trique faut-il privil√©gier en contexte bancaire ?  
b. Y a-t-il des variables probl√©matiques ?  
c. Quel algorithme offre le meilleur compromis Precision/Recall ?  

<details>
  <summary><strong>üí°</strong></summary>

a. Recall si le but est de minimiser les faux n√©gatifs (ne pas accorder de pr√™t risqu√©)  
b. **√âthique**‚ÄØ: attention aux variables sensibles (`sex`, `age`)  
b. XGBoost ou Random Forest selon les runs  

</details>

---

### E. Interpr√©tation et restitution

1. Cliquez sur le nom d'un mod√®le: Parcourez **Interpretation ‚Üí Feature importance, Partial dependence**, puis **Performance ‚Üí Confusion Matrix**
2. Cr√©er un dashboard : Dans la barre du haut, √† gauche des ... > Dashboards**+ New Dashboard ‚Üí risk_dashboard**
3. Ajouter : **New Tile** Feature importance, Confusion matrix(saved model report> Add Model> Saved model report options), et un bloc **Text** avec une synth√®se des r√©sultats (Pour Feature Importance, vous pouvez aussi exporter des rapports sous forme de datasets depuis les pages des mod√®les)
4. Publier le dashboard

### Questions

a. Quelle variable contribue le plus √† la pr√©diction ?  
b. Comment le seuil influence-t-il la matrice de confusion ?

<details>
  <summary><strong>üí°</strong></summary>

a. `duration`  
b. Augmenter le seuil = augmente les FP (perte potentielle de clients) / baisser le seuil = augmente les FN (risque de d√©faut) ‚Üí seuil √† d√©terminer selon la tol√©rance au risque.

**Exemple de synth√®se pour le dashboard** : 
Ce mod√®le de scoring pr√©dit le risque de d√©faut avec une AUC de 0,82 (avis ?). Les variables importantes sont la dur√©e et le montant du pr√™t, toutes deux corr√©l√©es n√©gativement √† la probabilit√© de remboursement. Ce mod√®le constitue un outil d'aide √† la d√©cision pour les conseillers.

</details>

---

### V√©rification du Flow

Le Flow doit pr√©senter les noeuds suivants :

<img width="1103" height="234" alt="image" src="https://github.com/user-attachments/assets/ae8364aa-80f5-4869-8062-2bb4c1c76779" />


Si un dataset interm√©diaire est cr√©√© (par exemple `risk_prepared_code`), il doit √™tre l'entr√©e de la recette de scoring.

> **Astuce** : tout projet Dataiku peut √™tre export√© sous forme de *bundle* (**Administration ‚Üí Bundles ‚Üí Export**) pour √™tre r√©utilis√© sur un autre espace. Cette fonctionnalit√© permet de partager un pipeline complet sans devoir tout recr√©er.

<details>
  <summary><strong></strong></summary>

---
   
## Perspective m√©tier

Le scoring de clients estime la probabilit√© de d√©faut de paiement d'un client dans le cadre d'octroi d'un cr√©dit.
En contexte bancaire :

- Utilit√© : pr√©-tri des dossiers pour √©tude plus pouss√©e des cas risqu√©s
- M√©trique : Recall prioritaire car les faux n√©gatifs sont co√ªteux
- √âthique : variables sensibles (sexe, √¢ge) √† encadrer/contr√¥ler/justifier, voire exclure, en cas de mise en prod r√©elle
- Variables cl√©s : `duration`, `amount`, `payment_intensity`

---

## Ressources

- Dataiku Academy - *Classification Models* : <https://academy.dataiku.com/latest/course-detail/dataiku-ml-practitioner.html>
- Documentation - *Machine Learning in Dataiku* : <https://doc.dataiku.com/dss/latest/machine-learning/index.html>
- Hastie, Tibshirani, Friedman - *The Elements of Statistical Learning* (PDF libre) : <https://hastie.su.domains/ElemStatLearn/>

</details>

---

<small>[**Page d'accueil**](https://github.com/rsquaredata/atelier_dataiku/blob/main/README.md)</small>
