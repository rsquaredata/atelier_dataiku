# Module 1 - Scoring de clients : exploration et modÃ©lisation supervisÃ©e

## 1. Introduction et objectifs

Ce module guide la crÃ©ation d'un modÃ¨le de scoring de crÃ©dit sous Dataiku Cloud.
Le jeu de donnÃ©es utilisÃ© est `credit_scoring.csv`, importÃ© puis renommÃ© `risk` dans Dataiku.
Les Ã©tapes suivantes permettent de prÃ©parer les donnÃ©es, d'entraÃ®ner un modÃ¨le supervisÃ© et d'interprÃ©ter ses rÃ©sultats.

Objectifs pÃ©dagogiques :
- Importer, renommer et explorer un jeu de donnÃ©es dans Dataiku Cloud
- Nettoyer et transformer les variables pour la modÃ©lisation
- EntraÃ®ner et Ã©valuer un modÃ¨le de classification binaire
- InterprÃ©ter les mÃ©triques principales et les variables explicatives
- Construire un tableau de bord de restitution

---

## 2. Rappels thÃ©oriques - statistiques descriptives et classification supervisÃ©e

### Variables
- Variable cible : binaire $y \in \{0,1\}$ (1 = bon payeur, 0 = mauvais payeur)
- Variables explicatives : quantitatives  (revenu, montant, durÃ©e) ou qualitatives (emploi, situation familiale)

### RÃ©gression logistique

$$
P(y_i=1 \mid X_i)=\frac{1}{1+e^{-(\beta_0+\beta_1x_{i1}+\ldots+\beta_p x_{ip})}}
$$

Chaque coefficient $\beta_j$ reflÃ¨te l'influence de la variable $x_j$ sur la probabilitÃ© d'appartenir Ã  la classe 1.
RÃ©gularisation L1 (Lasso) : $\lambda\sum|\beta_j|$ ; L2 (Ridge) : $\lambda\sum\beta_j^2$

### Ã‰valuation du modÃ¨le

| Indicateur | Formule | InterprÃ©tation |
|-------------|----------|----------------|
| Accuracy | $$\frac{TP+TN}{TP+TN+FP+FN}$$ | Pourcentage de prÃ©dictions correctes |
| Recall (SensibilitÃ©) | $$\frac{TP}{TP+FN}$$ | CapacitÃ© Ã  dÃ©tecter les cas positifs |
| Precision | $$\frac{TP}{TP+FP}$$ | FiabilitÃ© des cas prÃ©dits positifs |
| F1-score | $$2\,\frac{\text{Precision}\times \text{Recall}}{\text{Precision}+\text{Recall}}$$ | Compromis Precision-Recall |
| AUC (ROC) | Aire sous la courbe ROC | Pouvoir discriminant global |

### CorrÃ©lation et colinÃ©aritÃ©

$$
r_{XY}=\frac{\mathrm{Cov}(X,Y)}{s_X s_Y},\quad |r|>0{,}8 \Rightarrow \text{variables redondantes.}
$$

### Glossaire intÃ©grÃ©

| Terme | DÃ©finition |
|--------|-------------|
| AutoML | EntraÃ®nement automatique de plusieurs algorithmes |
| Feature importance | Poids relatif d'une variable dans la performance |
| Overfitting | Sur-ajustement aux donnÃ©es d'entraÃ®nement |
| Threshold | Seuil de probabilitÃ© sÃ©parant les classes 0/1 |
| AUC | Aire sous la courbe ROC, proche de 1 = meilleur modÃ¨le |

---

## 3. TP - Scoring clients

> PrÃ©-requis : disposer localement de `credit_scoring.csv`.

### A. CrÃ©ation du projet et import du dataset

1. Ouvrir <https://profile.dataiku.com/> â†’ Start free trial â†’ Dataiku Cloud
2. CrÃ©er un nouveau projet : **+ New Project â†’ Blank project**
   - Project name : `Dataiku_Bank_[PrenomNom]`
   - Key : `DB_[initiales]`
3. Importer le fichier : **Flow â†’ + Dataset â†’ Files â†’ Upload your files** â†’ sÃ©lectionner `credit_scoring.csv` â†’ Create
4. Renommer le dataset : **More actions (...) â†’ Rename â†’ risk**
5. VÃ©rifier le schÃ©ma : **Schema â†’** vÃ©rifier les types (numÃ©rique vs catÃ©goriel) â†’ Save

### Questions

a. Quelle est la variable cible ?  
b. Combien le dataset contient-il d'observations et de variables ?

<details>
  <summary><strong>ğŸ’¡</strong></summary>

a. Variable cible : `credit_risk`  
b. Dimensions : 1 000 observations et 21 variables

</details>

---

### B. Exploration initiale

1. Ouvrir `risk` â†’ **Explore**
2. **Charts** : histogrammes pour `amount`, `duration`, `age`
3. **Statistics â†’ Missing values** : repÃ©rer les Ã©ventuelles valeurs manquantes
4. **Statistics â†’ Correlation matrix** : repÃ©rer les variables corrÃ©lÃ©es
5. **Charts â†’ Scatter** (`amount` vs `duration`) ; **Facet** par `credit_risk`

### Questions

a. Quelle variable prÃ©sente la plus forte asymÃ©trie ?  
b. Quelle variable semble la plus corrÃ©lÃ©e au risque ?  
c. Y a-t-il des valeurs manquantes ?  
d. Quelles relations observe-t-on entre `amount`, `age` et `duration` ?

<details>
  <summary><strong>ğŸ’¡</strong></summary>

a. `amount` (trÃ¨s asymÃ©trique)  
b. `duration` (corrÃ©lation nÃ©gative modÃ©rÃ©e avec `credit_risk`)  
c. Aucune valeur manquante  
d. `age` faiblement positif avec bon crÃ©dit ; `amount` et `duration` associÃ©s Ã  plus de dÃ©fauts quand ils augmentent

</details>

---

### C. PrÃ©paration des donnÃ©es et Code recipe

1. Depuis le **Flow**, sÃ©lectionner `risk` â†’ **+ Recipe â†’ Prepare â†’ Output : risk_prepared â†’ Create**
2. Nettoyer les noms de colonnes : **Columns â†’ Rename columns** (`personal_status_sex`, `credit_history`, etc.)
3. CrÃ©er la variable `payment_intensity` : **+ Add step â†’ Formula â†’ New column : payment_intensity â†’ Expression : amount / nullif(duration,0)**
4. Recoder `personal_status_sex` : **+ Add step â†’ If... Then... Else â†’ New column : Gender_bin**
   - Si `personal_status_sex` âˆˆ {female div/dep/mar, female single} alors 1, sinon 0
   - Forcer le type en **Integer**
5. Encodage de `job` : **+ Add step â†’ Encoding â†’ One-Hot encoding â†’ Columns : job â†’ Drop original : Yes**
6. ExÃ©cuter la recette : **Run â†’** vÃ©rifier la crÃ©ation de `risk_prepared`

#### Code recipe

1. **Flow â†’ + Recipe â†’ Code â†’ Python**
2. Input : `risk_prepared` ; Output : `risk_prepared` (ou `risk_prepared_code` si remplacer ne passe pas)
3. Coller le code suivant :

```python
import pandas as pd, numpy as np
df = input_dataset.copy()
df["log_amount"] = np.log1p(df["amount"])
output_dataset = df
```

4. ExÃ©cuter la recette : **Run â†’** vÃ©rifier l'apparition de la colonne `log_amount`

### Questions

a. Combien de colonnes reste-t-il aprÃ¨s prÃ©paration ?  
b. Quelle transformation amÃ©liore la lisibilitÃ© des montants ?  
c. Pourquoi utiliser `log1p` plutÃ´t que `log` ?  
d. Quelle est la moyenne et l'Ã©cart-type de `log_amount` ?

<details>
  <summary><strong>ğŸ’¡</strong></summary>

a. 26  
b. La transformation logarithmique  
c. `log1p` calcule $\log(1+x)$ : il gÃ¨re $x=0$ et stabilise les trÃ¨s petites valeurs, utile en finance (micro-paiements, taux d'intÃ©rÃªt, arrondis, ...)  
d. Moyenne : â‰ˆ 7.15 ; Ã©cart-type : â‰ˆ 0.88

</details>

---

### D. Construction du modÃ¨le

1. SÃ©lectionner `risk_prepared` (ou `risk_prepared_code`) â†’ **Lab â†’ + New â†’ Visual analysis â†’ Predict**
2. Target : `credit_risk` ; Prediction type : Binary classification
3. Features : garder toutes les colonnes utiles, exclure identifiants
4. **Design â†’ Algorithms** : cocher Logistic Regression, Random Forest, XGBoost
5. **Train â†’ Start**
6. **Performance** : observer Accuracy, Recall, Precision, F1, AUC
7. **Deploy â†’ Create Scoring recipe â†’ Output : risk_predictions â†’ Create â†’ Run**

### Questions

a. Ã€ votre avis, quelle mÃ©trique faut-il privilÃ©gier en contexte bancaire ?  
b. Y a-t-il des variables problÃ©matiques ?  
b. Quel algorithme offre le meilleur compromis Precision/Recall ?  

<details>
  <summary><strong>ğŸ’¡</strong></summary>

a. Recall si le but est de minimiser les faux nÃ©gatifs (ne pas accorder de prÃªt risquÃ©)  
b. - **Ã‰thique**â€¯: attention aux variables sensibles (`sex`, `age`)  
b. XGBoost ou Random Forest selon les runs  

</details>

---

### 3.5. InterprÃ©tation et restitution

1. Depuis la page du modÃ¨le : **Interpretation â†’ Feature importance, Partial dependence**
2. CrÃ©er un dashboard : **+ New â†’ Dashboard â†’ risk_dashboard**
3. Ajouter : Feature importance, Confusion matrix, et un bloc **Text** avec une synthÃ¨se des rÃ©sultats
4. Publier le dashboard

### Questions

a. Quelle variable contribue le plus Ã  la prÃ©diction ?  
b. Comment le seuil influence-t-il la matrice de confusion ?

<details>
  <summary><strong>ğŸ’¡</strong></summary>

a. `duration` ressort souvent en tÃªte  
b. Augmenter le seuil = augmente les FP (perte potentielle de clients) / baisser le seuil = augmente les FN (risque de dÃ©faut) â†’ seuil Ã  dÃ©terminer selon la tolÃ©rance au risque.

**Exemple de synthÃ¨se pour le dashboard** : 
Ce modÃ¨le de scoring prÃ©dit le risque de dÃ©faut avec une AUC de 0,82 (c'est bien ?). Les variables importantes sont la durÃ©e et le montant du prÃªt, toutes deux corrÃ©lÃ©es nÃ©gativement Ã  la probabilitÃ© de remboursement. Ce modÃ¨le constitue un outil d'aide Ã  la dÃ©cision pour les conseillers.

### VÃ©rification du Flow

Le Flow doit prÃ©senter les noeuds suivants :

```
risk â†’ risk_prepared â†’ (code) â†’ risk_predictions â†’ risk_dashboard
```

Si un dataset intermÃ©diaire est crÃ©Ã© (par exemple `risk_prepared_code`), il doit Ãªtre l'entrÃ©e de la recette de scoring.

</details>

---

## 4. Perspective mÃ©tier

Le scoring de crÃ©dit estime la probabilitÃ© de dÃ©faut d'un client.
En contexte bancaire :

- UtilitÃ© : prÃ©-tri des dossiers pour Ã©tude plus poussÃ©e des cas risquÃ©s
- MÃ©trique : Recall prioritaire car les faux nÃ©gatifs sont coÃ»teux
- Ã‰thique : variables sensibles (sexe, Ã¢ge) Ã  encadrer/contrÃ´ler/justifier voire exclure en cas de mise en prod rÃ©elle
- Variables clÃ©s : `duration`, `amount`, `payment_intensity`

---

## 5. Ressources

- Dataiku Academy - *Classification Models* : <https://academy.dataiku.com/latest/course-detail/dataiku-ml-practitioner.html>
- Documentation - *Machine Learning in Dataiku* : <https://doc.dataiku.com/dss/latest/machine-learning/index.html>
- Hastie, Tibshirani, Friedman - *The Elements of Statistical Learning* (PDF libre) : <https://hastie.su.domains/ElemStatLearn/>
