# Atelier Dataiku

DurÃ©e : 2h00  
Objectif : DÃ©couvrir les fonctions essentielles de **Dataiku Cloud** Ã  travers deux cas mÃ©tiers en finance.

---

## I. Mise en route (10 min)

### Objectif
DÃ©couvrir lâ€™interface et lâ€™organisation dâ€™un projet, crÃ©er son premier projet.

1. Connectez-vous Ã  [https://profile.dataiku.com/](https://profile.dataiku.com/).
2. Cliquez sur **Start Free Trial** â†’ **Dataiku Cloud**.
3. CrÃ©ez un projet :  
   - **+ New Project â†’ Blank Project**  
   - Nom : `Dataiku_Bank_[PrÃ©nomNom]`  
   - Key : `DB_[initiales]`
4. Explorez les onglets : **Flow**, **Datasets**, **Recipes**, **Models**, **Dashboards**.
5. Importez le premier jeu de donnÃ©es :  
   - Fichier : `credit_scoring.csv`  
   - Type : *CSV uploaded*  
   - VÃ©rifiez le schÃ©ma automatiquement dÃ©tectÃ©.

ğŸ“¦ **Dataset crÃ©Ã© :** `credit_scoring`

**Questions :**
- Quelle est la variable cible dans ce dataset ?  
- Combien dâ€™observations et de variables contient-il ?  
- Quels types de variables sont prÃ©sentes ?

<details>
<summary>ğŸ’¡ CorrigÃ©</summary>

- Cible : `credit_risk` (1 = bon crÃ©dit, 0 = mauvais crÃ©dit).  
- Dimensions : 1000 lignes, 21 colonnes.  
- Types : numÃ©riques (`duration`, `amount`, `age`, â€¦), catÃ©gorielles (`job`, `housing`, â€¦).
</details>

---

## II. Scoring de crÃ©dit (60 min)

### Objectif
CrÃ©er un modÃ¨le de scoring pour prÃ©dire la probabilitÃ© quâ€™un client fasse dÃ©faut sur son crÃ©dit.

---

### A. Explorer les donnÃ©es (10 min)

1. Cliquez sur le dataset `credit_scoring`.  
2. Onglet **Explore** (ou *Statistics* selon la version).  
3. Parcourez les histogrammes automatiques.  
4. Identifiez les variables numÃ©riques, catÃ©gorielles, et la cible `credit_risk`.

ğŸ“¦ **Dataset utilisÃ© :** `credit_scoring`

**Questions :**
- Quelle variable prÃ©sente la plus forte asymÃ©trie ?  
- Quelle variable semble la plus corrÃ©lÃ©e avec le risque de dÃ©faut ?  
- Y a-t-il des valeurs manquantes ?  
- Quelle relation entre `amount`, `age` et `duration` ?

<details>
<summary>ğŸ’¡ CorrigÃ©</summary>

- AsymÃ©trie : `amount` et `people_liable`.  
- CorrÃ©lation : `duration` et `amount` (corrÃ©lation nÃ©gative).  
- Pas de valeurs manquantes dÃ©tectÃ©es.  
- Plus le montant et la durÃ©e augmentent, plus le risque croÃ®t.
</details>

---

### B. PrÃ©parer le dataset (20 min)

1. CrÃ©ez une **Prepare Recipe**.  
2. Nettoyez/normalisez les noms de colonnes.  
3. Transformez les variables catÃ©gorielles :  
   - Recoder `personal_status_sex` pour crÃ©er `Gender_bin` (1 = femme, 0 = homme).  
   - Utilisez un *One-Hot encoding* pour la variable `job`.  
4. CrÃ©ez une nouvelle variable :  
   `payment_intensity = amount / duration`
5. Supprimez uniquement les colonnes redondantes ou peu informatives (ex. `telephone` ou `people_liable` si jugÃ©es inutiles).  
6. Ajoutez une **Code Recipe** (Python) :

```python
import pandas as pd, numpy as np
df = input_dataset.copy()
df["log_income"] = np.log1p(df["income"])
output_dataset = df
```

ğŸ“¦ **Dataset crÃ©Ã© :** `credit_scoring_prepared`

**Questions :**
- Combien de colonnes restent aprÃ¨s prÃ©paration ?  
- Quelle transformation pourrait amÃ©liorer la lisibilitÃ© du jeu ?  
- Pourquoi utiliser `log1p` plutÃ´t quâ€™un simple `log` ?  
- Quelle est la moyenne et lâ€™Ã©cart-type de `log_amount` ?

<details>
<summary>ğŸ’¡ CorrigÃ©</summary>

- Environ 25 colonnes aprÃ¨s encodage.  
- On peut centrer-rÃ©duire (`Standardize`) les variables numÃ©riques.  
- `log1p` gÃ¨re les zÃ©ros et stabilise les petites valeurs.  
- Moyenne â‰ˆ 7.2, Ã©cart-type â‰ˆ 0.8 (Ã  vÃ©rifier selon Ã©chelle).  
</details>

---

### C. Construire un modÃ¨le AutoML (20 min)

1. Dans le **Flow**, cliquez sur `credit_scoring_prepared`.  
2. Ouvrez le **Lab â†’ Visual analysis â†’ Predict**.  
3. Variable cible : `credit_risk`.  
4. Laissez Dataiku sÃ©lectionner les *features*.  
5. Testez plusieurs algorithmes : *Logistic Regression*, *Random Forest*, *XGBoost*.  
6. Comparez leurs performances dans **Model results â†’ Metrics**.

ğŸ“¦ **Dataset crÃ©Ã© :** `credit_scoring_predictions` (via *Apply Model*)

**Questions :**
- Quel modÃ¨le obtient le meilleur AUC ?  
- Quelles variables dominent ? Certaines posent-elles un problÃ¨me Ã©thique ?  
- Quelle mÃ©trique privilÃ©gier en contexte bancaire ?

<details>
<summary>ğŸ’¡ CorrigÃ©</summary>

- Meilleur AUC : souvent *Random Forest* ou *XGBoost*.  
- Variables dominantes : `duration`, `amount`, `age`.  
- Variables sensibles : `sex`, `age`. Ã€ surveiller.  
- MÃ©trique clÃ© : *Recall* ou *F1* selon le risque mÃ©tier.
</details>

---

### D. InterprÃ©ter et restituer (10 min)

1. Ouvrez lâ€™onglet **Model Results â†’ Interpretation**.  
2. Consultez *Feature importance* et *Partial Dependence*.  
3. CrÃ©ez un Dashboard â€œCredit Scoringâ€ avec :  
   - un graphique dâ€™importance des variables,  
   - une matrice de confusion,  
   - un texte de conclusion.  
4. Publiez le dashboard (*View â†’ Publish*).

ğŸ“¦ **Dashboard crÃ©Ã© :** `Credit_Scoring_Dashboard`

**Question :**
> En une phrase : comment une banque pourrait-elle utiliser ce modÃ¨le ?

<details>
<summary>ğŸ’¡ CorrigÃ©</summary>

> Pour prÃ©qualifier automatiquement les dossiers clients et prioriser les cas Ã  analyser manuellement.
</details>

---

## III. DÃ©tection de fraude (40 min)

### Objectif
Identifier les transactions suspectes dans un flux de paiements.

### A. Importer et explorer (10 min)

1. Importez le fichier `creditcard.csv`.  
2. VÃ©rifiez les colonnes : `Time`, `Amount`, `Class`.  
3. Renommez `Class` â†’ `is_fraud`.  
4. Comptez les fraudes (`is_fraud = 1`).

ğŸ“¦ **Dataset crÃ©Ã© :** `creditcard`

**Questions :**
- Quelle proportion de fraudes ?  
- Les fraudes concernent-elles les gros montants ?

<details>
<summary>ğŸ’¡ CorrigÃ©</summary>

- â‰ˆ 0,17 % de fraudes (492 / 284807).  
- Les montants moyens sont lÃ©gÃ¨rement plus Ã©levÃ©s, mais la mÃ©diane est infÃ©rieure.
</details>

---

### B. Ã‰chantillonner pour lâ€™analyse (10 min)

1. CrÃ©ez une **Sample/Filter Recipe**.  
2. RÃ©duisez Ã  10 000 lignes, conservez une proportion rÃ©aliste de fraudes (~0,5 %).  
3. CrÃ©ez une colonne `hour = floor(Time / 3600) % 24`.

ğŸ“¦ **Dataset crÃ©Ã© :** `creditcard_sampled`

**Questions :**
- Pourquoi faut-il Ã©quilibrer le jeu dâ€™apprentissage ?  
- Quelles stratÃ©gies alternatives (SMOTE, undersampling, class weights) ?

<details>
<summary>ğŸ’¡ CorrigÃ©</summary>

- Ã‰quilibrer amÃ©liore la sensibilitÃ© du modÃ¨le (*Recall*) et Ã©vite que lâ€™Accuracy masque le dÃ©sÃ©quilibre.  
- Alternatives : *SMOTE* (ajoute des cas minoritaires synthÃ©tiques), *undersampling*, ou *class weights*.
</details>

---

### C. Lancer un modÃ¨le AutoML (15 min)

1. Depuis `creditcard_sampled`, crÃ©ez un projet **Predict (Lab)**.  
2. Cible : `is_fraud`.  
3. Testez plusieurs modÃ¨les et comparez les mÃ©triques AUC, Recall, Precision, F1.  
4. Appliquez le meilleur modÃ¨le â†’ `creditcard_predictions`.

ğŸ“¦ **Dataset crÃ©Ã© :** `creditcard_predictions`

**Questions :**
- Pourquoi lâ€™Accuracy nâ€™est-elle pas une bonne mÃ©trique ici ?  
- Quel modÃ¨le maximise le Recall sans trop sacrifier la Precision ?  
- Comment pondÃ©rer les mÃ©triques selon le coÃ»t mÃ©tier ?

<details>
<summary>ğŸ’¡ CorrigÃ©</summary>

- Lâ€™Accuracy reste Ã©levÃ©e mÃªme si le modÃ¨le ignore les fraudes (classe majoritaire).  
- *XGBoost* ou *Random Forest* avec *class weights* donnent souvent le meilleur Recall.  
- PondÃ©ration : privilÃ©gier le Recall si le coÃ»t dâ€™une fraude non dÃ©tectÃ©e est plus Ã©levÃ©.
</details>

---

### D. Visualisation finale (5 min)

1. CrÃ©ez un Dashboard â€œFraudeâ€ avec :  
   - score de fraude par montant,  
   - diagramme â€œfraude vs non fraudeâ€,  
   - rÃ©partition horaire (`hour`).

ğŸ“¦ **Dashboard crÃ©Ã© :** `Fraud_Dashboard`

**Questions :**
- Les transactions Ã  haut montant sont-elles plus frauduleuses ?  
- Ã€ quelle heure les fraudes sont-elles les plus frÃ©quentes ?

<details>
<summary>ğŸ’¡ CorrigÃ©</summary>

- Tendance dispersÃ©e : quelques gros montants trÃ¨s suspects, mais beaucoup de petites fraudes.  
- Pic nocturne (2â€“5h), probablement en heures creuses.
</details>

---

### Transition vers le BONUS

> Nous allons maintenant enrichir notre pipeline avec des composants dâ€™intelligence gÃ©nÃ©rative et dâ€™automatisation, pour passer dâ€™un modÃ¨le prÃ©dictif Ã  un systÃ¨me intelligent complet.

---

## IV. BONUS â€“ Intelligence gÃ©nÃ©rative, Agents et Automatisation

### A. Explication automatique des dÃ©cisions

1. SÃ©lectionnez `credit_scoring_predictions`.  
2. CrÃ©ez une **LLM Prompt Recipe** :  

```text
Tu es analyste risques dans une banque.
RÃ©sume en 2-3 phrases pourquoi ce dossier a Ã©tÃ© classÃ© "risquÃ©".
Mentionne les 2 facteurs les plus importants.
```

ğŸ“¦ **Dataset crÃ©Ã© :** `credit_explanations`

---

### B. GÃ©nÃ©ration dâ€™un rapport synthÃ©tique

1. SÃ©lectionnez le dataset dâ€™Ã©valuation du modÃ¨le (`evaluation_store`).  
2. CrÃ©ez une **LLM Prompt Recipe** avec :  

```text
Tu es data scientist dans une banque.
RÃ©dige une synthÃ¨se sur le modÃ¨le :
- performances (AUC, F1, Recall, Precision)
- variables clÃ©s
- limites et pistes dâ€™amÃ©lioration
```

ğŸ“¦ **Dataset crÃ©Ã© :** `executive_summary.md`

---

### C. Agent intelligent : Risk Analyst Bot

1. Dans **Automation â†’ Agents**, crÃ©ez un agent `RiskAnalystBot`.  
2. DÃ©finissez un **Trigger** : `is_fraud_pred = 1`.  
3. Ajoutez des actions :  
   - GÃ©nÃ©rer un rÃ©sumÃ© automatique (LLM).  
   - Ã‰tablir une checklist mÃ©tier.  
   - Exporter les cas Ã  examiner vers `cases_to_review.csv`.  
   - Notifier lâ€™Ã©quipe via e-mail.

ğŸ“¦ **Dataset crÃ©Ã© :** `cases_to_review.csv`

---

### D. Automatisation du pipeline

1. Dans **Automation â†’ Scenarios**, crÃ©ez un scÃ©nario `Auto_Fraud_Pipeline`.  
2. Ã‰tapes :  
   - *Build dataset* (`creditcard_sampled`)  
   - *Run model training* (`FraudDetection_XGBoost`)  
   - *Run LLM Recipe* (`RiskExplanation`)  
   - *Export CSV* (`cases_to_review.csv`)  
   - *Send mail* (rÃ©sumÃ© du rapport).  
3. Ajoutez un *Trigger* horaire (tous les jours Ã  8h).

---

### E. Suivi des performances (Health Check)

1. CrÃ©ez un dataset `llm_logs` contenant les prompts et rÃ©sultats LLM.  
2. Calculez : taux de succÃ¨s, temps moyen, cohÃ©rence.  
3. CrÃ©ez un Dashboard â€œLLM Performanceâ€.  
4. Ajoutez un scÃ©nario â€œHealthCheck_LLMâ€ dÃ©clenchÃ© chaque soir pour alerter si >5 % dâ€™erreurs.

ğŸ“¦ **Dataset crÃ©Ã© :** `llm_logs`

---

### F. Vue dâ€™ensemble du pipeline final

1. PrÃ©paration et scoring des crÃ©dits/fraudes  
2. Explication automatique des dÃ©cisions  
3. Rapport exÃ©cutif gÃ©nÃ©rÃ© par LLM  
4. Agent virtuel rÃ©actif  
5. ScÃ©nario automatisÃ©  
6. Monitoring des performances IA

---

> En combinant **Dataiku DSS**, les **LLM Recipes**, les **Agents** et les **Scenarios**, vous obtenez un **pipeline complet et automatisÃ©** : les modÃ¨les prÃ©disent, expliquent, agissent et se surveillent.
